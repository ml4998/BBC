{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b434b7bd-3dbd-47d9-a91f-fdb2b5da2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3a1584-be73-4f12-89e7-8feb5fa5cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_director_name = \"David Lynch\"\n",
    "str_director_name = \"Wong Kar Wai\"\n",
    "str_director_name = str_director_name.replace(\" \", \"%20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c3354d-85b1-4e5e-b3da-15185ac0cdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://www.imdb.com/search/name/?name=Wong%20Kar%20Wai' request=<Request url='https://www.imdb.com/search/name/?name=Wong%20Kar%20Wai' method='GET'>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(f\"https://www.imdb.com/search/name/?name={str_director_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96319e0-93d5-43fc-b9b2-6f9bf1996cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.locator('.ipc-lockup-overlay').nth(0).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c90f3f-f3de-4ce5-a609-edfa93adfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f744b87d-76b2-4431-b6c1-744bf79a9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = await page.content()\n",
    "soup_doc = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d061de8c-c058-41f3-bba1-c67ef2ae52f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tag_born \u001b[38;5;241m=\u001b[39m soup_doc\u001b[38;5;241m.\u001b[39mfind(class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipc-metadata-list-item__label\u001b[39m\u001b[38;5;124m\"\u001b[39m,string \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBorn\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m tag_next_container \u001b[38;5;241m=\u001b[39m \u001b[43mtag_born\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241m.\u001b[39mnext\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#.next.next.find(class_=\"ipc-metadata-list-item__list-content-item\").text\u001b[39;00m\n\u001b[1;32m      6\u001b[0m tag_birth_origin \u001b[38;5;241m=\u001b[39m  tag_next_container\u001b[38;5;241m.\u001b[39mfind(class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipc-metadata-list-item__list-content-item\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "tag_born = soup_doc.find(class_ = \"ipc-metadata-list-item__label\",string = re.compile('Born'))\n",
    "tag_next_container = tag_born.next.next\n",
    "\n",
    "#.next.next.find(class_=\"ipc-metadata-list-item__list-content-item\").text\n",
    "tag_birth_origin =  tag_next_container.find(class_=\"ipc-metadata-list-item__list-content-item\")\n",
    "\n",
    "tag_birth_origin.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef84766-fdd2-4367-b417-65ebdd76c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe as directors \n",
    "\n",
    "lst_birth = []\n",
    "for str_director_name in directors:\n",
    "\n",
    "    # this gets the string to search for with playwright\n",
    "    str_director_name = str_director_name.replace(\" \", \"%20\")  \n",
    "    print(f\"https://www.imdb.com/search/name/?name={str_director_name}\")\n",
    "\n",
    "    \n",
    "    #this goes to the website\n",
    "    await page.goto(f\"https://www.imdb.com/search/name/?name={str_director_name}\")\n",
    "\n",
    "    #click on director's profile\n",
    "    await page.locator(\".ipc-title-link-wrapper\").click()\n",
    "\n",
    "\n",
    "    #get the born string\n",
    "\n",
    "    #append origin to lst_birth\n",
    "\n",
    "\n",
    "#assign lst_birth as birth column in dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11c451-e607-4f38-aec8-56627b1d9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144b6ad-ea44-4bb8-8b97-5a5a59d162bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"backup_BBC1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1a762-8378-4491-bd62-1aa7b408f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"backup_BBC1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32438cc-b7b3-46cb-95a2-c6690c2daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c33d8-26cc-472b-bea1-1987d2d3aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = list(df['director'].unique())\n",
    "d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba3a74-acf1-424a-bc75-9ff5b6f65470",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for d in d_list:\n",
    "    if \" and \" in d:\n",
    "        dir_name = d.split(\" and \")\n",
    "        names.extend(dir_name)\n",
    "    else:\n",
    "        names.append(d)\n",
    "\n",
    "names    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2abcd30-26e7-4e5c-8a26-da3836e3eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1059a-a17f-434c-9afb-a1cecb552bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Outside\n",
    "head = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "\n",
    "url_list = []\n",
    "\n",
    "for dir in names:\n",
    "    #print(dir)\n",
    "\n",
    "    try:\n",
    "        url = \"https://www.imdb.com/search/name/?name=\" + name.replace(\" \", \"%20\")\n",
    "        raw_html = requests.get(url, headers=head).content\n",
    "        soup_doc = BeautifulSoup(raw_html, \"html.parser\")\n",
    "        \n",
    "# For director in directors:\n",
    "# Modified in loop\n",
    "#name = \"Terrence Malick\"\n",
    "#url = \"https://www.imdb.com/search/name/?name=\" + name.replace(\" \", \"%20\")\n",
    "#raw_html = requests.get(url, headers=head).content\n",
    "# time.sleep(2)\n",
    "#soup_doc = BeautifulSoup(raw_html, \"html.parser\")\n",
    "#print(type(soup_doc))\n",
    "#print(soup_doc.prettify())\n",
    "\n",
    "# Use soup to get the link\n",
    "        a_tag = soup_doc.find('h3').previous\n",
    "#print(David_link)\n",
    "\n",
    "        href = a_tag['href']\n",
    "#print(David_href)\n",
    "\n",
    "        full_urls = \"imdb.com\" + href\n",
    "        #print(full_urls)\n",
    "\n",
    "        dictionary = {'director_name': name, 'full_urls': full_urls}\n",
    "        print(dictionary)\n",
    "        (url_list.append(dictionary)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle the exception (you can customize this part based on your needs)\n",
    "        #print(f\"An error occurred for director {dir}\")\n",
    "        #none_string = f\"An error occurred for director {dir}\"\n",
    "        dictionary = {'director_name': name, 'full_urls': None}\n",
    "                        \n",
    "        print(dictionary)\n",
    "        url_list.append(dictionary)\n",
    "        continue  # Continue to the next iteration of the loop\n",
    "\n",
    "\n",
    "# Once you get the link, you want to put it in a list of dict: dir_name and link\n",
    "# {name: \"David Lynch\", link: \"/name/nm0000186/?ref_=sr_t_1\"}\n",
    "\n",
    "# Step 2: Loop through your list of dicts and go to the links:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Malick_link = soup_doc.find('a')['href']\n",
    "#print(Malick_link)\n",
    "\n",
    "#full_Malick = \"imdb.com\" + Malick_link\n",
    "#print(full_Malick)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1313e3a-4553-415c-adad-49ac3206ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "\n",
    "url_list = []\n",
    "#the loop variable needs to be name not dir so that the lines work\n",
    "# and the try needs to happen after the download.\n",
    "for name in names:\n",
    "    print(name)\n",
    "    url = \"https://www.imdb.com/search/name/?name=\" + name.replace(\" \", \"%20\")\n",
    "    raw_html = requests.get(url, headers=head).content\n",
    "    soup_doc = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    try:\n",
    "        a_tag = soup_doc.find('h3').previous\n",
    "        href = a_tag['href']\n",
    "        full_urls = \"imdb.com\" + href\n",
    "        print(full_urls)\n",
    "        dictionary = {'director_name': name, 'full_urls': full_urls}\n",
    "        url_list.append(dictionary) # you have url_lis instead of url_list\n",
    "    except:\n",
    "        print(name + \" no link\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150d6c1-e59d-42ea-ac09-e5613c6749e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5ea8d-375a-4ac3-8bdf-d06ca0d93b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_links = pd.DataFrame(url_list)\n",
    "df_dir_links.to_csv(r'backup_BBC_dir_links.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76658353-e1d5-471b-8fee-fe12adb20d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#head = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "#{'director_name': 'Sarah Polley', 'full_urls': 'imdb.com/name/nm0001631/?ref_=sr_t_1'}\n",
    "#for dir in url_list:\n",
    "    #try:\n",
    "        #search_url = \"http://www.\" + dir['full_urls']\n",
    "        #response = requests.get(search_url, headers=head)\n",
    "        #soup_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "        #section=soup_doc.find_all('section', attrs={'data-testid': 'PersonalDetails'})[0]\n",
    "        #birthplace = section.ul.find_all('li')[2].find_all('a')[-1].text\n",
    "        #dir['birthplace']=birthplace\n",
    "        #print(birthplace)\n",
    "    #except:\n",
    "        #print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49adb19c-98c1-4af6-b9c9-e189c40e23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "#{'director_name': 'Sarah Polley', 'full_urls': 'imdb.com/name/nm0001631/?ref_=sr_t_1'}\n",
    "for dir in url_list:\n",
    "    try:\n",
    "        search_url = \"http://www.\" + dir['full_urls']\n",
    "        response = requests.get(search_url, headers=head)\n",
    "        soup_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "        birthplace = section=soup_doc.find_all(string='Born')[-1].parent.parent.find_all('a')[-1].text\n",
    "        dir['birthplace']=birthplace\n",
    "        print(birthplace)\n",
    "    except:\n",
    "        print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a4e86-a7de-46ed-8e30-3dc0da557225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52400d04-c62f-413f-8ca2-7e5237072d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_birthplace = pd.DataFrame(url_list)\n",
    "df_birthplace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cba647-3acd-4bd4-9b28-3e7ee5a174a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_birthplace.to_csv(r'backup_BBC_birthplace.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3539d0b-118f-4124-b8e2-713ffb5bc295",
   "metadata": {},
   "outputs": [],
   "source": [
    "for place in dir:\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "    keys = {'address': place['birthplace'], 'key': 'AIzaSyB6ym3C_xC5kgd2nRv5F8GQSyX9lc84FH8'}\n",
    "    r = requests.get(url,params=keys)\n",
    "    result_dic = r.json()\n",
    "    try:\n",
    "        lat = result_dic['results'][0]['geometry']['location']['lat']\n",
    "        long = result_dic['results'][0]['geometry']['location']['lng']\n",
    "        coords = []\n",
    "        coords.append(long)\n",
    "        coords.append(lat)\n",
    "        mygeometry = {'place': place, 'geometry.type': 'Point','geometry.coordinates':coords}\n",
    "        place[\"geometry.type\"] = 'Point'\n",
    "        place[\"geometry.coordinates\"] = coords\n",
    "        print(mygeometry)\n",
    "    except:\n",
    "        print(place)\n",
    "\n",
    "\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fe0f0-8f4d-413a-a609-9cbd976da4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So just make sure that you are looping through that final list of dictionary's, that has the directors name and birthplace and link. And this will add the proper geometry to those dictionaries.\n",
    "#so you need to change the name your_list_of_dicts to what you have\n",
    "#And then put your API key where I have enter_your_key_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99ecd3-aa59-4221-968a-12326d4e0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for name in url_list:\n",
    "    print(name)\n",
    "    url = \"https://www.\" + name[\"full_urls\"]\n",
    "    raw_html = requests.get(url, headers=head).content\n",
    "    soup_doc = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    try:\n",
    "        a_tag = soup_doc.find('h3').previous\n",
    "        href = a_tag['href']\n",
    "        full_urls = \"imdb.com\" + href\n",
    "        print(full_urls)\n",
    "        dictionary = {'director_name': name, 'full_urls': full_urls}\n",
    "        url_list.append(dictionary) # you have url_lis instead of url_list\n",
    "    except:\n",
    "        print(name + \" no link\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15121845-1c98-415f-b06f-46548a8a72f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/name/nm0945981/?ref_=sr_t_1\"\n",
    "raw_html = requests.get(url, headers=head).content\n",
    "soup_doc = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    try:\n",
    "        #birthplace\n",
    "        a_tag = soup_doc.find('h3').previous\n",
    "        href = a_tag['href']\n",
    "        full_urls = \"imdb.com\" + href\n",
    "        print(full_urls)\n",
    "        dictionary = {'director_name': name, 'full_urls': full_urls}\n",
    "        url_list.append(dictionary) # you have url_lis instead of url_list\n",
    "    except:\n",
    "        print(name + \" no link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2d4f7-646f-4a11-8045-b7af9374c2fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "        #find the birthplace\n",
    "        birthplace = soup_doc.find.a\n",
    "        name['birthplace']=birthplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90eb752-0d3d-47eb-abd2-5fccb4df726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#birthplace = soup_doc.find('a', class_=\"ipc-metadata-list-item__list-content-item--link\")\n",
    "print(birthplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46ddc5-766f-4fe7-b256-332bb408cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#birthplace = soup_doc.find('a', class_=\"ipc-metadata-list-item__list-content-item\")\n",
    "if birthplace:\n",
    "    print(birthplace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074d408-8ea6-49f8-b745-5cf0e92706b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary1 = []\n",
    "\n",
    "for birthcountry in url_list:\n",
    "    try:\n",
    "        search_url = \"http://www.\" + dir_birthcountry['link']\n",
    "        response = requests.get(search_url, headers=head)\n",
    "        soup_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        tag_born = soup_doc.find(class_=\"ipc-metadata-list-item__label\", string=re.compile('Born'))\n",
    "        tag_next_container = tag_born.next.next\n",
    "\n",
    "        tag_birth_origin = tag_next_container.find(class_=\"ipc-metadata-list-item__list-content-item\")\n",
    "\n",
    "        birthorigin = tag_birth_origin.text\n",
    "\n",
    "        country_dictionary = {'director_name': birthcountry['name'],\n",
    "                              'birthcountry': birthorigin}\n",
    "        \n",
    "        print(country_dictionary)\n",
    "\n",
    "        dictionary.append(country_dictionary)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        country_dictionary = {'director_name': birthcountry['name'],\n",
    "                              'birthcountry': None}\n",
    "        \n",
    "        print(country_dictionary)\n",
    "        dictionary.append(country_dictionary)\n",
    "        continue \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacdb87-abff-4649-a135-be4998597114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for place in you_list_of_dicts:\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "    keys = {'address': place['birthcountry'], 'key': 'enter_your_key_here'}\n",
    "    r = requests.get(url,params=keys)\n",
    "    result_dic = r.json()\n",
    "    try:\n",
    "        lat = result_dic['results'][0]['geometry']['location']['lat']\n",
    "        long = result_dic['results'][0]['geometry']['location']['lng']\n",
    "        coords = []\n",
    "        coords.append(long)\n",
    "        coords.append(lat)\n",
    "        mygeometry = {'place': place, 'geometry.type': 'Point','geometry.coordinates':coords}\n",
    "        place[\"geometry.type\"] = 'Point'\n",
    "        place[\"geometry.coordinates\"] = coords\n",
    "        print(mygeometry)\n",
    "    except:\n",
    "        print(place)\n",
    "\n",
    "\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a261fb-8d94-489f-bdd5-1a3806f0487c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
